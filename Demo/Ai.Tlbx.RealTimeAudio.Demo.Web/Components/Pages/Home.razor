@page "/"
@using Ai.Tlbx.RealTimeAudio.OpenAi
@using Ai.Tlbx.RealTimeAudio.OpenAi.Models
@using Ai.Tlbx.RealTimeAudio.OpenAi.Tools
@using Ai.Tlbx.RealTimeAudio.OpenAi.Tools.BuiltInTools
@using Ai.Tlbx.RealTime.WebUi.Components
@using Ai.Tlbx.RealTimeAudio.Demo.Web
@using static Ai.Tlbx.RealTimeAudio.OpenAi.Models.LogLevel
@rendermode InteractiveServer
@inject OpenAiRealTimeApiAccess rta
@inject IJSRuntime JS
@implements IDisposable

<PageTitle>AI Voice Chat</PageTitle>

<CascadingValue Value="rta">
    <CascadingValue Value="sessionSettings">
        <div class="container mx-auto p-4">
            <div class="flex flex-col lg:flex-row gap-4">
                <!-- Controls Panel -->
                <div class="lg:w-1/3">
                    <div class="bg-white rounded-lg shadow-md p-4 mb-4">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">Voice Controls</h3>

                        <div class="flex gap-2 mb-4">
                            <AiTalkControl OnStartTalking="StartSession" OnStopTalking="StopSession" IsTalking="rta.IsRecording" Loading="rta.IsConnecting || rta.IsRecording" />
                        </div>

                        <div class="mb-4">
                            <label for="voiceSelect" class="block text-sm font-medium text-gray-700 mb-1">Assistant Voice</label>
                            <VoiceSelect SelectedVoice="@currentVoiceString" SelectedVoiceChanged="OnVoiceChanged" Disabled="@rta.IsConnecting" />
                        </div>

                        <!-- Microphone selection dropdown -->
                        <div class="mb-4">
                            <MicrophoneSelect AvailableMicrophones="availableMicrophones" 
                                             SelectedMicrophoneId="selectedMicrophoneId" 
                                             MicPermissionGranted="micPermissionGranted" 
                                             OnRequestPermission="RequestMicrophonePermission" />
                        </div>

                        <div class="mb-4 flex items-center">
                            <input type="checkbox" id="timeToolCheck" class="h-4 w-4 text-blue-600 border-gray-300 rounded focus:ring-blue-500 mr-2" 
                            @bind="useTimeTool" 
                            disabled="@rta.IsRecording"> 
                            <label for="timeToolCheck" class="text-sm font-medium text-gray-700">Enable Current Time Tool</label>
                        </div>

                        <div class="mt-4">
                            <button class="w-full py-2 px-4 rounded-md bg-gray-200 text-gray-800 font-medium hover:bg-gray-300 transition-colors flex items-center justify-center"
                            @onclick="ClearChat"
                            disabled="@(rta.IsConnecting)">
                                <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 mr-2" viewBox="0 0 20 20" fill="currentColor">
                                    <path fill-rule="evenodd" d="M9 2a1 1 0 00-.894.553L7.382 4H4a1 1 0 000 2v10a2 2 0 002 2h8a2 2 0 002-2V6a1 1 0 100-2h-3.382l-.724-1.447A1 1 0 0011 2H9zM7 8a1 1 0 012 0v6a1 1 0 11-2 0V8zm5-1a1 1 0 00-1 1v6a1 1 0 102 0V8a1 1 0 00-1-1z" clip-rule="evenodd" />
                                </svg>
                                Clear Chat
                            </button>
                        </div>

                        <div class="mt-4">
                            <MicTestWidget OnStartTest="TestMicrophone" Loading="rta.IsMicrophoneTesting || rta.IsConnecting" />
                        </div>

                        <div class="mb-4">
                            <StatusWidget ConnectionStatus="rta.ConnectionStatus" Error="rta.LastErrorMessage" IsMicrophoneTesting="rta.IsMicrophoneTesting" />
                        </div>

                        <div class="mt-4">
                            <DiagnosticsWidget @ref="diagnosticsWidget" InitiallyExpanded="false" 
                                               BufferLevel="0" 
                                               Latency="0" 
                                               SampleRate="24000" 
                                               AudioChunksProcessed="0" />
                        </div>
                    </div>
                </div>

                <!-- Chat Panel -->
                <div class="lg:w-2/3">
                    <div class="bg-white rounded-lg shadow-md h-[600px] flex flex-col">
                        <div class="p-4 border-b border-gray-200">
                            <h3 class="text-xl font-bold text-gray-800">Conversation</h3>
                        </div>

                        <div class="flex-1 p-4 overflow-y-auto space-y-4" id="chat-messages" @ref="chatContainer">
                            <ChatWidget />
                        </div>

                        <div class="p-3 border-t border-gray-200 bg-gray-50 text-sm text-gray-600">
                            @if (rta.IsRecording)
                            {
                                <div class="flex items-center">
                                    <div class="relative h-3 w-3 mr-2">
                                        <span class="animate-ping absolute h-3 w-3 rounded-full bg-red-400 opacity-75"></span>
                                        <span class="absolute h-3 w-3 rounded-full bg-red-500"></span>
                                    </div>
                                    <span>Listening... Just speak naturally.</span>
                                </div>
                            }
                            else
                            {
                                <span>Click Start to begin recording</span>
                            }
                        </div>
                    </div>
                </div>
            </div>
            <ToastNotification @ref="toastNotification" />
        </div>
    </CascadingValue>
</CascadingValue>

@code 
{
    private ElementReference chatContainer;
    private string currentVoiceString = string.Empty;
    private bool useTimeTool = true;
    
    // Microphone selection related fields
    private List<MicrophoneSelect.MicrophoneInfo> availableMicrophones = new();
    private string selectedMicrophoneId = string.Empty;
    private bool micPermissionGranted = false;

    private SessionSettingsContext sessionSettings = new();
    private ToastNotification? toastNotification;
    private DiagnosticsWidget? diagnosticsWidget;

    protected override async Task OnInitializedAsync()
    {
        rta.OnConnectionStatusChanged = OnConnectionStatusChanged;
        rta.OnMessageAdded = OnMessageAdded;
        rta.OnMicrophoneDevicesChanged = OnMicrophoneDevicesChanged;
        
        // Listen for recording state changes
        PropertyChanged += OnPropertyChanged;

        // Initialize the string value based on the current enum value
        currentVoiceString = rta.CurrentVoice.ToString().ToLower();

        // Don't check for microphone permission in OnInitializedAsync (during prerender)
        // We'll do that in OnAfterRenderAsync instead
        await Task.CompletedTask;
    }
    
    // Simple property changed handler to detect recording state changes
    private void OnPropertyChanged(object? sender, EventArgs e)
    {
        // Make sure to preserve mic permission state even when recording state changes
        if (!micPermissionGranted && availableMicrophones.Count > 0)
        {
            micPermissionGranted = true;
            InvokeAsync(StateHasChanged);
        }
    }
    
    // Logging method using the centralized logging system
    private void Log(LogLevel level, string message)
    {
        rta.LogMessage(level, $"[Home] {message}");
    }
    
    // Simulate a property changed event for state monitoring
    private event EventHandler? PropertyChanged;
    
    private void RaisePropertyChanged()
    {
        PropertyChanged?.Invoke(this, EventArgs.Empty);
    }

    private async Task CheckMicrophonePermission()
    {
        try
        {
            // Try to get microphones - this will succeed if permission is already granted
            var mics = await rta.GetAvailableMicrophones();
            
            // Check if we have actual device information - actual device labels mean permission is granted
            bool hasRealDeviceNames = mics.Count > 0 && 
                mics.Any(m => !string.IsNullOrEmpty(m.Name) && !m.Name.StartsWith("Microphone "));
            
            micPermissionGranted = hasRealDeviceNames;
            Log(LogLevel.Info, $"Initial permission check: Permission granted: {micPermissionGranted}, Found {mics.Count} microphones");
            
            if (micPermissionGranted)
            {
                // If we got devices with real names, permission is granted
                availableMicrophones = mics.Select(m => new MicrophoneSelect.MicrophoneInfo
                {
                    Id = m.Id,
                    Name = m.Name,
                    IsDefault = m.IsDefault
                }).ToList();
                
                // Select default or first microphone
                if (availableMicrophones.Count > 0)
                {
                    var defaultMic = availableMicrophones.FirstOrDefault(m => m.IsDefault);
                    selectedMicrophoneId = defaultMic?.Id ?? availableMicrophones[0].Id;
                    await rta.SetMicrophoneDevice(selectedMicrophoneId);
                    
                    Log(LogLevel.Info, $"Initially selected microphone: {availableMicrophones.FirstOrDefault(m => m.Id == selectedMicrophoneId)?.Name ?? "Unknown"}");
                }
            }
            else if (mics.Count > 0)
            {
                // We have devices but without proper labels - this suggests permission is needed
                // but we still store them for when permission is granted
                availableMicrophones = mics.Select(m => new MicrophoneSelect.MicrophoneInfo
                {
                    Id = m.Id,
                    Name = m.Name,
                    IsDefault = m.IsDefault
                }).ToList();
                Log(LogLevel.Info, "Microphones found but without proper labels - permission needed");
            }
            else
            {
                Log(LogLevel.Warn, "No microphones found or permission not granted");
            }
        }
        catch (Exception ex)
        {
            Log(LogLevel.Error, $"Error checking microphone permission: {ex.Message}");
            Log(LogLevel.Error, $"Stack trace: {ex.StackTrace}");
            micPermissionGranted = false;
        }
        finally
        {
            await InvokeAsync(StateHasChanged);
        }
    }

    private async Task CheckMicrophonePermissionState()
    {
        try
        {
            // Check if permission is already granted without activating microphone
            var permissionState = await JS.InvokeAsync<string>("eval", @"
                (async function() {
                    try {
                        const permission = await navigator.permissions.query({name: 'microphone'});
                        return permission.state;
                    } catch (e) {
                        return 'prompt';
                    }
                })()
            ");
            
            Log(LogLevel.Info, $"Microphone permission state: {permissionState}");
            
            if (permissionState == "granted")
            {
                // Permission is already granted, get device list WITHOUT activating microphone
                micPermissionGranted = true;
                
                var mics = await rta.GetAvailableMicrophones();
                availableMicrophones = mics.Select(m => new MicrophoneSelect.MicrophoneInfo
                {
                    Id = m.Id,
                    Name = m.Name,
                    IsDefault = m.IsDefault
                }).ToList();
                
                // Select default or first microphone but DON'T set it yet
                if (availableMicrophones.Count > 0)
                {
                    var defaultMic = availableMicrophones.FirstOrDefault(m => m.IsDefault);
                    selectedMicrophoneId = defaultMic?.Id ?? availableMicrophones[0].Id;
                    Log(LogLevel.Info, $"Permission granted - found {mics.Count} microphones, selected: {availableMicrophones.FirstOrDefault(m => m.Id == selectedMicrophoneId)?.Name ?? "Unknown"}");
                }
            }
            else
            {
                // Permission not granted, don't activate microphone
                micPermissionGranted = false;
                availableMicrophones = new List<MicrophoneSelect.MicrophoneInfo>();
                Log(LogLevel.Info, "Microphone permission not granted - will request when user clicks grant access");
            }
        }
        catch (Exception ex)
        {
            Log(LogLevel.Error, $"Error checking microphone permission state: {ex.Message}");
            micPermissionGranted = false;
        }
        finally
        {
            await InvokeAsync(StateHasChanged);
        }
    }

    private async Task RequestMicrophonePermission()
    {
        try
        {
            // Instead of setting isLoadingMicrophones, we'll rely on micPermissionGranted for UI state
            // isLoadingMicrophones = true;
            await InvokeAsync(StateHasChanged);

            Log(LogLevel.Info, "Explicitly requesting microphone permission...");
            
            // Use the new method that explicitly requests permission and gets labeled devices
            var deviceInfos = await rta.RequestMicrophonePermissionAndGetDevices();
            
            // Convert to MicrophoneInfo objects
            availableMicrophones = deviceInfos.Select(m => new MicrophoneSelect.MicrophoneInfo
            {
                Id = m.Id,
                Name = m.Name,
                IsDefault = m.IsDefault
            }).ToList();
            
            // Check if we now have devices with real names (not placeholders)
            micPermissionGranted = deviceInfos.Count > 0 && 
                deviceInfos.Any(m => !string.IsNullOrEmpty(m.Name) && !m.Name.StartsWith("Microphone "));
            
            Log(LogLevel.Info, $"After permission request: Permission granted: {micPermissionGranted}, Found {deviceInfos.Count} microphones");
            
            // If we have microphones with permission, select one
            if (micPermissionGranted && availableMicrophones.Count > 0)
            {
                // Try to find default microphone
                var defaultMic = availableMicrophones.FirstOrDefault(m => m.IsDefault);
                if (defaultMic != null)
                {
                    selectedMicrophoneId = defaultMic.Id;
                }
                else if (availableMicrophones.Count > 0)
                {
                    // Otherwise use the first microphone
                    selectedMicrophoneId = availableMicrophones[0].Id;
                }

                // Set the selected device
                if (!string.IsNullOrEmpty(selectedMicrophoneId))
                {
                    await rta.SetMicrophoneDevice(selectedMicrophoneId);
                    var selectedMic = availableMicrophones.FirstOrDefault(m => m.Id == selectedMicrophoneId);
                    Log(LogLevel.Info, $"Selected microphone: {selectedMic?.Name ?? "Unknown"}");
                }
            }
            else
            {
                Log(LogLevel.Warn, "Permission not granted or no microphones with labels found");
            }
        }
        catch (Exception ex)
        {
            Log(LogLevel.Error, $"Error requesting microphone permission: {ex.Message}");
            Log(LogLevel.Error, $"Stack trace: {ex.StackTrace}");
        }
        finally
        {
            // isLoadingMicrophones = false;
            await InvokeAsync(StateHasChanged);
        }
    }

    private async Task OnVoiceChanged(string newVoice)
    {
        currentVoiceString = newVoice;
        rta.CurrentVoice = Enum.Parse<AssistantVoice>(newVoice, true);
        sessionSettings = sessionSettings with { SelectedVoice = newVoice };
        await Task.CompletedTask;
    }

    private void OnMicrophoneDevicesChanged(List<AudioDeviceInfo> devices)
    {
        InvokeAsync(async () => 
        {
            availableMicrophones = devices.Select(m => new MicrophoneSelect.MicrophoneInfo
            {
                Id = m.Id,
                Name = m.Name,
                IsDefault = m.IsDefault
            }).ToList();
            await Task.CompletedTask;
            StateHasChanged();
        });
    }

    private void OnConnectionStatusChanged(string status)
    {
        InvokeAsync(async () => 
        {
            if (!string.IsNullOrEmpty(status) && toastNotification != null)
            {
                await toastNotification.ShowAsync(status, "Connection Status", ToastNotification.ToastType.Info);
            }
            await Task.CompletedTask;
            StateHasChanged();
        });
    }

    private void OnMessageAdded(OpenAiChatMessage message)
    {
        InvokeAsync(async () => {
            StateHasChanged();
            await Task.Delay(50); // Give the DOM time to update
            await ScrollToBottom();
        });
    }

    private async Task ScrollToBottom()
    {
        try
        {
            await JS.InvokeVoidAsync("scrollToBottom", chatContainer);
        }
        catch
        {
            // Ignore JS interop errors
        }
    }

    private async Task StartSession()
    {
        try
        {
            // Store the currently selected device before starting the session
            string deviceToUse = selectedMicrophoneId;
            string deviceName = availableMicrophones.FirstOrDefault(m => m.Id == deviceToUse)?.Name ?? "default device";
            
            // Apply the selected microphone if it has a value
            if (!string.IsNullOrEmpty(deviceToUse))
            {
                await rta.SetMicrophoneDevice(deviceToUse);
                Log(LogLevel.Info, $"Using microphone: {deviceName} for recording session");
            }

            // Get current settings or create new settings
            var settings = rta.Settings;

            // Add TimeTool if enabled
            if (useTimeTool)
            {
                settings.Tools = [new TimeTool()];
            }
            
            // Start the session with the configured settings
            await rta.Start(settings);
            
            // Even if permission state is lost in the process, we still know we have a valid device
            if (!micPermissionGranted && availableMicrophones.Count > 0)
            {
                micPermissionGranted = true;
            }
            
            await InvokeAsync(StateHasChanged);
        }
        catch (Exception ex)
        {
            Log(LogLevel.Error, $"Error starting session: {ex.Message}");
            Log(LogLevel.Error, $"Stack trace: {ex.StackTrace}");
        }
    }

    private async Task StopSession()
    {
        try
        {
            await rta.Stop();
            
            // Ensure mic permission state is preserved after stopping
            RaisePropertyChanged();
            
            await InvokeAsync(StateHasChanged);
        }
        catch (Exception ex)
        {
            Log(LogLevel.Error, $"Error stopping session: {ex.Message}");
            Log(LogLevel.Error, $"Stack trace: {ex.StackTrace}");
        }
    }    

    private void ClearChat()
    {
        rta.ClearChatHistory();
        InvokeAsync(StateHasChanged);
    }

    private async Task TestMicrophone()
    {
        try
        {
            // Store the currently selected device before testing
            string deviceToUse = selectedMicrophoneId;
            string deviceName = availableMicrophones.FirstOrDefault(m => m.Id == deviceToUse)?.Name ?? "default device";
            
            // Apply the selected microphone if it has a value
            if (!string.IsNullOrEmpty(deviceToUse))
            {
                await rta.SetMicrophoneDevice(deviceToUse);
                Log(LogLevel.Info, $"Testing microphone: {deviceName}");
            }
            
            await rta.TestMicrophone();
            
            // Even if permission state is lost in the process, we still know we have a valid device
            if (!micPermissionGranted && availableMicrophones.Count > 0)
            {
                micPermissionGranted = true;
            }
            
            await InvokeAsync(StateHasChanged);
        }
        catch (Exception ex)
        {
            Log(LogLevel.Error, $"Error testing microphone: {ex.Message}");
            Log(LogLevel.Error, $"Stack trace: {ex.StackTrace}");
        }
    }

    public void Dispose()
    {
        rta.OnConnectionStatusChanged = null;
        rta.OnMessageAdded = null;
        rta.OnMicrophoneDevicesChanged = null;
        PropertyChanged -= OnPropertyChanged;
    }

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        if (firstRender)
        {
            // Add JS helper function for scrolling
            await JS.InvokeVoidAsync("eval", @"
                window.scrollToBottom = function(element) {
                    if (element) {
                        element.scrollTop = element.scrollHeight;
                    }
                }
            ");

            // Check microphone permission state without activating microphone
            await CheckMicrophonePermissionState();
        }
    }

    // Helper function to format JSON for display
    private string FormatJson(string? jsonString)
    {
        if (string.IsNullOrWhiteSpace(jsonString))
        {    
            return "(empty)";
        }
        try
        {
            using var jsonDoc = System.Text.Json.JsonDocument.Parse(jsonString);
            return System.Text.Json.JsonSerializer.Serialize(jsonDoc, new System.Text.Json.JsonSerializerOptions { WriteIndented = true });
        }
        catch (System.Text.Json.JsonException)
        {
            // If it's not valid JSON, return the original string
            return jsonString;
        }
        catch (Exception ex)
        {
            return $"Error formatting JSON: {ex.Message}";
        }
    }

    // Helper function to truncate text
    private string TruncateText(string text, int maxLength)
    {
        if (string.IsNullOrEmpty(text) || text.Length <= maxLength)
            return text;
            
        return text.Substring(0, maxLength) + "...";
    }
}

